{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('ld3': conda)"
  },
  "interpreter": {
   "hash": "b3d5defd48bcce546b12f2e95f99040e967dfa98e52f7fab83451f06e037fab3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from skmultiflow.data import DataStream, MultilabelGenerator, ConceptDriftStream\n",
    "from skmultiflow.meta import ClassifierChain\n",
    "from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier\n",
    "from skmultiflow.bayes import NaiveBayes\n",
    "from skmultiflow.metrics import hamming_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss\n",
    "#from ld3 import LD3\n",
    "from skmultilearn.dataset import load_from_arff\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultiflow.drift_detection import ADWIN, EDDM, KSWIN, HDDM_W, HDDM_A, DDM, PageHinkley\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import util\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from river.metrics import ExampleF1\n",
    "from scipy.stats import truncnorm\n",
    "from tornados.drift_detection import fhddm, fhddms, fhddms_add, mddm_a, mddm_e, mddm_g, rddm, seq_drift2\n",
    "from ld3_ import LD3, Window, StreamGenerator\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "'''n_features = 100\n",
    "n_targets = 20\n",
    "s1 = MultilabelGenerator(n_samples=6000, n_features=n_features, n_targets=n_targets, n_labels=1, random_state=100) #100\n",
    "s2 = MultilabelGenerator(n_samples=6009, n_features=n_features, n_targets=n_targets, n_labels=2, random_state=250)\n",
    "stream = ConceptDriftStream(stream=s1, drift_stream=s2, position=4000, width=1, random_state=0)\n",
    "sample_size=10000'''\n",
    "\n",
    "gen = StreamGenerator()\n",
    "stream, sample_size, n_features, n_targets = gen.get_stream(type='sudden2')\n",
    "\n",
    "'''X, y = load_from_arff('./datasets/{}'.format('20NG.arff'), label_count=20)\n",
    "X = X.toarray()\n",
    "y = y.toarray().astype(np.int8)\n",
    "#X, y = util.induce_drift(X, y, 10000, 19300, 20, 1006, percentage=2)\n",
    "sample_size = len(X)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "if len(np.unique(y)) > 2:\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(y)\n",
    "\n",
    "n_targets = y.shape[1]\n",
    "stream = DataStream(data = X, y=y, n_targets=n_targets)'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"X, y = load_from_arff('./datasets/{}'.format('20NG.arff'), label_count=20)\\nX = X.toarray()\\ny = y.toarray().astype(np.int8)\\n#X, y = util.induce_drift(X, y, 10000, 19300, 20, 1006, percentage=2)\\nsample_size = len(X)\\nn_features = X.shape[1]\\n\\nif len(np.unique(y)) > 2:\\n    mlb = MultiLabelBinarizer()\\n    y = mlb.fit_transform(y)\\n\\nn_targets = y.shape[1]\\nstream = DataStream(data = X, y=y, n_targets=n_targets)\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "thresh = [2]\n",
    "for t in thresh:\n",
    "    detector = LD3(window_size=500, correlation_thresh=3, len=0, max_window_size=500) #20NG-0.06   Synthetic_sudden-0.01    tmc 0.4-4/5     imbd 0.15     ohsumed 0.5\n",
    "    clf = ClassifierChain(GaussianNB())#PassiveAggressiveClassifier(random_state=0))\n",
    "    pre_sample = [np.zeros(n_features), np.zeros(n_features)]\n",
    "    pre_label = [np.ones(n_targets), np.zeros(n_targets)]\n",
    "    clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "\n",
    "    stream.restart()\n",
    "    max_samples = sample_size\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pretrain_X = []\n",
    "    pretrain_y = []\n",
    "    p_bar = tqdm(total=max_samples)\n",
    "    n_samples = 0\n",
    "    drift, warning = False, False\n",
    "    correlation = 0\n",
    "    while n_samples < max_samples and stream.has_more_samples():\n",
    "        X, y = stream.next_sample()\n",
    "        #w_x.queue(X.flatten())\n",
    "        #w_y.queue(y)\n",
    "        #w_y.queue(y.flatten())\n",
    "        '''if n_samples % 60 == 0 and n_samples > 0:\n",
    "            clf.reset()\n",
    "            clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "            try:\n",
    "                clf.fit(w_x.get_window, w_y.get_window)\n",
    "            except:\n",
    "                clf.fit(np.array(pre_sample), np.array(pre_label))'''\n",
    "                \n",
    "        '''if n_samples >= 10000 and n_samples <= 10500:\n",
    "            pass\n",
    "            #print('Correlation @', n_samples, ': ', score, correlation)\n",
    "            #print(detector._average_correlation)\n",
    "            #r1, r2 = detector._ranks\n",
    "            #print('[',','.join(list(map(str,r1))), ']', '\\t[', ','.join(list(map(str,r2))), ']')'''\n",
    "        if drift:\n",
    "            print('Drift@', n_samples)\n",
    "            r1, r2 = detector._ranks\n",
    "            #print('[',','.join(list(map(str,r1))), ']', '\\t[', ','.join(list(map(str,r2))), ']')\n",
    "            clf.reset()\n",
    "            clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "            '''try:\n",
    "                clf.fit(w_x.get_window, w_y.get_window)\n",
    "            except:\n",
    "                w_x.queue(pre_sample[0])\n",
    "                w_x.queue(pre_sample[1])\n",
    "                w_y.queue(pre_label[0])\n",
    "                w_y.queue(pre_label[1])\n",
    "                clf.fit(w_x.get_window, w_y.get_window)'''\n",
    "\n",
    "        pred = clf.predict(X)\n",
    "        clf.partial_fit(X, np.array([y]))\n",
    "        #clf.partial_fit(X, y)\n",
    "        drift, warning, correlation, score = detector.update(pred.astype(np.int32))\n",
    "        #detector.add_element(np.all(pred.flatten() == y))\n",
    "\n",
    "        y_true.append(y)\n",
    "        #y_true.extend(y)\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "        p_bar.update(1)\n",
    "        n_samples += 1\n",
    "    p_bar.close()\n",
    "    stream.restart()\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(np.round(util.accuracy_example(np.array([y_true]), np.array([y_pred])), decimals=4)) # \n",
    "    print(np.round(util.hamming_loss(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(f1_score(np.array(y_true), np.array(y_pred), average='samples'),decimals=4))#util.f1_example(np.array([y_true]), np.array([y_pred])))\n",
    "    print(np.round(util.f1_micro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(util.f1_macro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b509d3c7c4746d098282236177980b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ce328950388c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m#clf.partial_fit(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/skmultiflow/meta/classifier_chains.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mXY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m--> 331\u001b[0;31m         return self._partial_fit(X, y, classes, _refit=False,\n\u001b[0m\u001b[1;32m    332\u001b[0m                                  sample_weight=sample_weight)\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ld3/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_pred = []\n",
    "results_true= y_true\n",
    "results_pred.append(y_pred)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c533de7f4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_true\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "detectors = [ADWIN(), EDDM(), DDM(), KSWIN(), HDDM_A(), HDDM_W()]\n",
    "for detector in detectors:\n",
    "    #detector = EDDM()#LD3(k=1, window_size=500)\n",
    "    clf = ClassifierChain(GaussianNB())#SGDClassifier(max_iter=1000, random_state=0))#\n",
    "    pre_sample = [np.zeros(n_features), np.zeros(n_features)]\n",
    "    pre_label = [np.ones(n_targets), np.zeros(n_targets)]\n",
    "    clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "\n",
    "    stream.restart()\n",
    "    max_samples = sample_size\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pretrain_X = []\n",
    "    pretrain_y = []\n",
    "    p_bar = tqdm(total=max_samples)\n",
    "    n_samples = 0\n",
    "    w_x = Window(max_size=199)\n",
    "    w_y = Window(max_size=199)\n",
    "    while n_samples < max_samples and stream.has_more_samples():\n",
    "        X, y = stream.next_sample()\n",
    "        #w_x.queue(X.flatten())\n",
    "        #w_y.queue(y)\n",
    "        if detector.detected_change():\n",
    "            print('Drift@', n_samples)\n",
    "            detector.reset()\n",
    "            clf.reset()\n",
    "            clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "            '''try:\n",
    "                clf.fit(w_x.get_window, w_y.get_window)\n",
    "            except:\n",
    "                clf.fit(np.array(pre_sample), np.array(pre_label))'''\n",
    "\n",
    "        pred = clf.predict(X)\n",
    "        clf.partial_fit(X, np.array([y]))\n",
    "        #clf.partial_fit(X, y)\n",
    "        #detector.add_element(pred.astype(np.int32))\n",
    "        #detector.add_element(np.all(pred.flatten() == y))\n",
    "        detector.add_element((pred.astype(np.int32).flatten().tolist())==(y.astype(np.int32).flatten().tolist()))\n",
    "\n",
    "        y_true.append(y)\n",
    "        #y_true.extend(y)\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "        p_bar.update(1)\n",
    "        n_samples += 1\n",
    "    \n",
    "    print()\n",
    "    print(np.round(util.accuracy_example(np.array([y_true]), np.array([y_pred])), decimals=4)) # \n",
    "    print(np.round(util.hamming_loss(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(f1_score(np.array(y_true), np.array(y_pred), average='samples'),decimals=4))#util.f1_example(np.array([y_true]), np.array([y_pred])))\n",
    "    print(np.round(util.f1_micro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(util.f1_macro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print()\n",
    "    results_pred.append(y_pred)\n",
    "   \n",
    "\n",
    "    stream.restart()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "detectors = [fhddm.FHDDM(), fhddms.FHDDMS(), fhddms_add.FHDDMS_add(), mddm_a.MDDM_A(), mddm_e.MDDM_E(), mddm_g.MDDM_G(), seq_drift2.SeqDrift2ChangeDetector(), rddm.RDDM()]\n",
    "for detector in detectors:\n",
    "    #detector = EDDM()#LD3(k=1, window_size=500)\n",
    "    clf = ClassifierChain(GaussianNB())#SGDClassifier(max_iter=1000, random_state=0))#\n",
    "    pre_sample = [np.zeros(n_features), np.zeros(n_features)]\n",
    "    pre_label = [np.ones(n_targets), np.zeros(n_targets)]\n",
    "    clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "\n",
    "    stream.restart()\n",
    "    max_samples = sample_size\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pretrain_X = []\n",
    "    pretrain_y = []\n",
    "    p_bar = tqdm(total=max_samples)\n",
    "    n_samples = 0\n",
    "    drift = False\n",
    "    w_x = Window(max_size=199)\n",
    "    w_y = Window(max_size=199)\n",
    "    while n_samples < max_samples and stream.has_more_samples():\n",
    "        X, y = stream.next_sample()\n",
    "        #w_x.queue(X.flatten())\n",
    "        #w_y.queue(y)\n",
    "        if drift:\n",
    "            print('Drift@', n_samples)\n",
    "            detector.reset()\n",
    "            clf.reset()\n",
    "            clf.fit(np.array(pre_sample), np.array(pre_label))\n",
    "            '''try:\n",
    "                clf.fit(w_x.get_window, w_y.get_window)\n",
    "            except:\n",
    "                clf.fit(np.array(pre_sample), np.array(pre_label))'''\n",
    "\n",
    "        pred = clf.predict(X)\n",
    "        clf.partial_fit(X, np.array([y]))\n",
    "        #clf.partial_fit(X, y)\n",
    "        #detector.add_element(pred.astype(np.int32))\n",
    "        #detector.add_element(np.all(pred.flatten() == y))\n",
    "        _, drift = detector.run((pred.astype(np.int32).flatten().tolist())==(y.astype(np.int32).flatten().tolist()))\n",
    "\n",
    "        y_true.append(y)\n",
    "        #y_true.extend(y)\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "        p_bar.update(1)\n",
    "        n_samples += 1\n",
    "    \n",
    "    print()\n",
    "    print(np.round(util.accuracy_example(np.array([y_true]), np.array([y_pred])), decimals=4)) # \n",
    "    print(np.round(util.hamming_loss(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(f1_score(np.array(y_true), np.array(y_pred), average='samples'),decimals=4))#util.f1_example(np.array([y_true]), np.array([y_pred])))\n",
    "    print(np.round(util.f1_micro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print(np.round(util.f1_macro(np.array(y_true), np.array(y_pred)), decimals=4))\n",
    "    print()\n",
    "    results_pred.append(y_pred)\n",
    "    \n",
    "    stream.restart()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(results_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accs_= []\n",
    "hamms_ = []\n",
    "f1exs_ = []\n",
    "f1mics_ = []\n",
    "f1macs_ = []\n",
    "\n",
    "for i in [0,1,5,14,6]:\n",
    "    index = len(results_pred[i]) // 25\n",
    "    accs= []\n",
    "    hamms = []\n",
    "    f1exs = []\n",
    "    f1mics = []\n",
    "    f1macs = []\n",
    "    for j in range(25):\n",
    "        accs.append(np.round(util.accuracy_example(np.array([results_true[j*index:(j+1)*index]]), np.array([results_pred[i][j*index:(j+1)*index]])), decimals=4))\n",
    "        hamms.append(np.round(util.hamming_loss(np.array(results_true[j*index:(j+1)*index]), np.array(results_pred[i][j*index:(j+1)*index])), decimals=4))\n",
    "        f1exs.append(np.round(f1_score(np.array(results_true[j*index:(j+1)*index]), np.array(results_pred[i][j*index:(j+1)*index]), average='samples'),decimals=4))\n",
    "        f1mics.append(np.round(util.f1_micro(np.array(results_true[j*index:(j+1)*index]), np.array(results_pred[i][j*index:(j+1)*index])), decimals=4))\n",
    "        f1macs.append(np.round(util.f1_macro(np.array(results_true[j*index:(j+1)*index]), np.array(results_pred[i][j*index:(j+1)*index])), decimals=4))\n",
    "    accs_.append(accs)\n",
    "    hamms_.append(hamms)\n",
    "    f1exs_.append(f1exs)\n",
    "    f1mics_.append(f1mics)\n",
    "    f1macs_.append(f1macs)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arange = np.arange(1, 101, step=4)\n",
    "colors = ['ro-', 'g^-', 'bx-', 'ms-', 'y*-']\n",
    "labels = ['LD3', 'ADWIN', 'HDDM_A', 'RDDM', 'ND']\n",
    "for i in range(5):\n",
    "    plt.plot(arange, accs_[i], colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Percentage of data')\n",
    "plt.xticks([0,20,40,60,80,100])\n",
    "plt.ylabel('Example-based accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arange = np.arange(1, 101, step=4)\n",
    "colors = ['ro-', 'g^-', 'bx-', 'ms-', 'y*-']\n",
    "labels = ['LD3', 'ADWIN', 'HDDM_A', 'RDDM', 'ND']\n",
    "for i in range(5):\n",
    "    plt.plot(arange, hamms_[i], colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Percentage of data')\n",
    "plt.xticks([0,20,40,60,80,100])\n",
    "plt.ylabel('Hamming Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arange = np.arange(1, 101, step=4)\n",
    "colors = ['ro-', 'g^-', 'bx-', 'ms-', 'y*-']\n",
    "labels = ['LD3', 'ADWIN', 'HDDM_A', 'RDDM', 'ND']\n",
    "for i in range(5):\n",
    "    plt.plot(arange, f1exs_[i], colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Percentage of data')\n",
    "plt.xticks([0,20,40,60,80,100])\n",
    "plt.ylabel('Example-based F1 score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arange = np.arange(1, 101, step=4)\n",
    "colors = ['ro-', 'g^-', 'bx-', 'ms-', 'y*-']\n",
    "labels = ['LD3', 'ADWIN', 'HDDM_A', 'RDDM', 'ND']\n",
    "for i in range(5):\n",
    "    plt.plot(arange, f1mics_[i], colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Percentage of data')\n",
    "plt.xticks([0,20,40,60,80,100])\n",
    "plt.ylabel('Micro-averaged F1 score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arange = np.arange(1, 101, step=4)\n",
    "colors = ['ro-', 'g^-', 'bx-', 'ms-', 'y*-']\n",
    "labels = ['LD3', 'ADWIN', 'HDDM_A', 'RDDM', 'ND']\n",
    "for i in range(5):\n",
    "    plt.plot(arange, f1macs_[i], colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Percentage of data')\n",
    "plt.xticks([0,20,40,60,80,100])\n",
    "plt.ylabel('Macro-averaged F1 score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "enron_preds = results_pred\n",
    "enron_true = results_true"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "model = KernelDensity(bandwidth=1e-1, kernel='gaussian')\n",
    "sample = np.array(correlation_list).reshape((len(correlation_list), 1))\n",
    "model.fit(sample)\n",
    "# sample probabilities for a range of outcomes\n",
    "values = np.asarray([value for value in np.linspace(-1,1,100)])\n",
    "values = values.reshape((len(values), 1))\n",
    "probabilities = model.score_samples(values)\n",
    "probabilities = np.exp(probabilities)\n",
    "# plot the histogram and pdf\n",
    "plt.hist(sample, bins=36, density=True)\n",
    "plt.plot(values[:], probabilities)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(accuracy_score(np.array(y_true), np.array(y_pred)))\n",
    "print(hamming_score(np.array(y_true), np.array(y_pred)))\n",
    "print(f1_score(np.array(y_true), np.array(y_pred), average='samples'))\n",
    "print(f1_score(np.array(y_true), np.array(y_pred), average='micro'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = np.array([1, 19, 3, 8, 5, 18, 4, 2, 0, 13, 11, 7, 17, 6, 9, 10, 12, 14, 15, 16])\n",
    "b = np.array([19, 1, 2, 7, 3, 5, 18, 17, 13, 4, 8, 11, 0, 10, 6, 12, 9, 14, 15, 16]) \n",
    "\n",
    "c = np.array([19, 1, 2, 17, 10, 18, 7, 8, 3, 12, 4, 6, 5, 13, 11, 9, 14, 15, 0, 16])\n",
    "d = np.array([19, 2, 1, 8, 18, 5, 17, 3, 13, 12, 4, 6, 7, 10, 11, 9, 14, 15, 16, 0]) \n",
    "\n",
    "x = np.array([ 1,8,19,5,13,0,17,2,18,11,3,6,9,10,12,4,7,14,15,16 ])\n",
    "y = np.array([ 19,2,1,8,18,10,12,5,3,4,7,6,11,9,13,17,14,0,15,16 ])\n",
    "\n",
    "e = np.array([ 8,19,17,1,3,5,0,9,18,2,4,6,11,7,13,12,10,14,15,16 ])\n",
    "f = np.array([ 19,1,2,8,7,18,5,3,4,13,11,10,17,0,6,12,9,14,15,16 ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "argx = (np.argsort(a)).astype(np.float)#np.arange(1,21,1).astype(np.float)\n",
    "argy = (np.argsort(b)).astype(np.float)#np.flip(np.arange(1,21,1)).astype(np.float) \n",
    "maxx = np.arange(1,21,1).astype(np.float)\n",
    "maxy = np.flip(np.arange(1,21,1)).astype(np.float) \n",
    "\n",
    "'''for i in range(20):\n",
    "    argx[i] *= 1/(argx[i]+1)\n",
    "    argy[i] *= 1/(argy[i]+1)\n",
    "    maxx[i] *= 1/(maxx[i]+1)\n",
    "    maxy[i] *= 1/(maxy[i]+1)'''\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(argx)\n",
    "print(argy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def WS(rx, ry):\n",
    "    sum_ = 0\n",
    "    ranks_x = np.argsort(rx)\n",
    "    ranks_y = np.argsort(ry)\n",
    "    for i in range(len(rx)):\n",
    "        sum_ += (1/(2**(ranks_x[i]))) * ((np.abs(ranks_x[i] - ranks_y[i]))/(np.max([np.abs(1-ranks_x[i]), np.abs(len(rx) - ranks_x[i])])))\n",
    "    return 1 - sum_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "WS(e,f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = [5,4,3,2,1]\n",
    "WS(a, b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "spearmanr(x[:5],y[:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial.distance import correlation\n",
    "correlation(argx,argy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dist(x, y, w):\n",
    "    sum_ = 0\n",
    "    for i in range(len(x)):\n",
    "        abs_ = np.abs(x[i] - y[i])\n",
    "        add =  abs_*w[i] if abs_ > 1 else 0\n",
    "        sum_ += add\n",
    "    return sum_\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial import distance\n",
    "((dist(argx, argy, w=1/((3)**(argy*argy))) / np.sqrt(len(argx))) + (dist(argx, argy, w=1/((3)**(argx*argx))) / np.sqrt(len(argx)))) / 2 #/ 0.05617535148406078"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rank_correlation(x, y, dist=distance.correlation):\n",
    "        c = np.array([dist(x[i], y[i]) * (1/((y[i]))) for i in range(len(x))]).sum()\n",
    "        return c\n",
    "rank_correlation(argx, argy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "1/argy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial import distance\n",
    "dist = distance.cityblock # * 1/((argy[i])**2)\n",
    "s = np.array([dist(argx[i], argy[i]) * 1/((argy[i])**2) for i in range(20)]).sum()\n",
    "\n",
    "'''for i in range(20):\n",
    "    s += dist(argx[i], argy[i]) * 1/((argy[i])**2)'''\n",
    "\n",
    "smax = 0\n",
    "for i in range(20):\n",
    "    smax += dist(argx[i], argx[i]) * 1/((argy[i])**2)\n",
    "\n",
    "print(s)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "0.5429113076754074\n",
    "55.77\n",
    "weigher = lambda r: 1/((1+r)**2)\n",
    "print(weightedtau(a,b,rank=True, additive=False, weigher=weigher))\n",
    "print(weightedtau(c,d,rank=True, additive=False, weigher=weigher))\n",
    "print(weightedtau(x,y,rank=True, additive=False, weigher=weigher))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.where(a==b)[0])\n",
    "print(np.where(c==d)[0])\n",
    "print(np.where(x==y)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weigher = lambda r: 1/((r+1))\n",
    "print(weightedtau(np.argsort(a),np.argsort(b),rank=False, additive=False, weigher=weigher))\n",
    "print(weightedtau(np.argsort(c),np.argsort(d),rank=False, additive=False, weigher=weigher))\n",
    "print(weightedtau(np.argsort(x),np.argsort(y),rank=False, additive=False, weigher=weigher))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}